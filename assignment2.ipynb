{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96d65995",
   "metadata": {},
   "source": [
    "Q1:Softmaxは数値を確率分布に変換する重要な関数です。PyTorchやNumPyを使わず、純粋なPythonで実装してください。\n",
    "\n",
    "softmax(x_i) = exp(x_i) / Σ exp(x_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd63ca9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def softmax(logits):\n",
    "    \"\"\"\n",
    "    純粋なPythonでsoftmax関数を実装\n",
    "    引数: logits - 数値のリスト、例: [2.0, 1.0, 0.1]\n",
    "    戻り値: 確率分布のリスト、すべての要素の合計が1.0\n",
    "    \n",
    "    例:\n",
    "    入力: [2.0, 1.0, 0.1]\n",
    "    出力: [0.659, 0.242, 0.099] (近似値)\n",
    "    \"\"\"\n",
    "    # 【TODO】この関数を実装してください\n",
    "    # ヒント手順:\n",
    "    # 1. 各数値に対して exp(x) を計算\n",
    "    # 2. すべてのexp値の合計を計算\n",
    "    # 3. 各exp値を合計で割る\n",
    "    pass\n",
    "\n",
    "# 実装をテスト\n",
    "test_logits = [2.0, 1.0, 0.1]\n",
    "probs = softmax(test_logits)\n",
    "print(f\"入力: {test_logits}\")\n",
    "print(f\"出力: {probs}\")\n",
    "print(f\"確率の合計: {sum(probs)}\")  # 1.0になるはず\n",
    "\n",
    "# 正確性を検証：PyTorchと比較\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "pytorch_probs = F.softmax(torch.tensor(test_logits), dim=0).tolist()\n",
    "print(f\"PyTorchの結果: {pytorch_probs}\")\n",
    "print(f\"実装は正しい: {all(abs(a - b) < 0.001 for a, b in zip(probs, pytorch_probs))}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
