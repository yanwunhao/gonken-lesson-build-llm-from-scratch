{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9aa538d",
   "metadata": {},
   "source": [
    "# レッスン 05 GPT-2とNanoGPT\n",
    "\n",
    "GPT-2は2019年に発表された際、OpenAIは重要な発見を示しました。Transformerベースの言語モデルを前例のない規模まで拡大すると——GPT-1の1億1700万パラメータから15億パラメータへと増加させ、より大規模で高品質なウェブテキストで訓練すると、モデルは驚くべき能力を示すようになりました。長い一貫性のあるテキストを生成できるだけでなく、より重要なことに、次の単語を予測するという単純な訓練目標だけで、モデルは明示的に訓練されていない様々なタスク——翻訳、質問応答、要約、さらには簡単な算術計算まで——を実行できることを証明しました。この「言語モデルは教師なしマルチタスク学習器である」という理念は、NLPモデルの訓練に対する私たちの理解を根本的に変えました。\n",
    "\n",
    "GPT-2は技術的には純粋なDecoderアーキテクチャのTransformerを採用し、元のTransformerのエンコーダー部分を取り除いて、モデル構造をより簡潔で統一的なものにしました。12層から48層のTransformerブロックを使用し、各ブロックにはマルチヘッド自己注意機構とフィードフォワードニューラルネットワークが含まれ、層正規化と残差接続が組み合わされています。この一見シンプルなアーキテクチャは、慎重に選別された40GBのWebTextデータセットで訓練することで、強力な言語理解と生成能力を示しました。\n",
    "\n",
    "nanoGPTはAndrej Karpathyが作成した教育プロジェクトで、最小限のコードでGPT-2のコア機能を再現することを目的としています。実装全体は約300行のPythonコードのみですが、GPTアーキテクチャの重要なコンポーネント——因果的自己注意機構、位置エンコーディング、層正規化、そして自己回帰生成——を完全に実装しています。自分のノートパソコンで小規模なGPTを訓練できます。例えば、シェイクスピアの作品集でシェイクスピア風のテキストを生成できるモデルを訓練したり、簡単な数学データセットで加算ができるモデルを訓練したりできます。この極めてシンプルな実装により、私たちは各行のコードの役割を真に理解し、エンジニアリングの最適化や複雑な訓練技術に隠されることなく、Transformerの本質を明確に見ることができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b957b7",
   "metadata": {},
   "source": [
    "## GPT-2について\n",
    "\n",
    "![GPT2Scaling](https://github.com/yanwunhao/gonken-lesson-build-llm-from-scratch/blob/main/figs/scaling_laws.png?raw=true)\n",
    "\n",
    "この図はGPT-2論文の中核的な発見を示しています。4つのグラフはそれぞれ異なるNLPタスクにおいて、モデルサイズ（117Mから1.5Bパラメータ）が増加するにつれてゼロショット性能がどのように向上するかを示しています。\n",
    "\n",
    "最も重要な観察は、すべてのタスクで一貫した傾向が見られることです——パラメータ数が増えるにつれて、性能が対数的に向上しています。これは「スケーリング則」の初期の証拠であり、後のGPT-3やそれ以降の大規模言語モデル開発の基礎となりました。\n",
    "\n",
    "![GPTzeroshot](https://github.com/yanwunhao/gonken-lesson-build-llm-from-scratch/blob/main/figs/zero-shot.png?raw=true)\n",
    "\n",
    "この本質的に示しているのは、十分に大きな言語モデルは、次の単語を予測するという単純な目標で訓練されただけで、明示的な指示なしに多様なタスクを実行する能力を獲得するということです。\n",
    "\n",
    "これが「言語モデルは教師なしマルチタスク学習器」というGPT-2の中心的な主張です。\n",
    "\n",
    "nanoGPTの文脈では、この同じアーキテクチャ——ただしはるかに小さいスケールで——がどのように実装されているかを学生に示すことができます。\n",
    "\n",
    "スケールは異なっても、基本的な原理は同じです：自己回帰的な次トークン予測を通じて、モデルは言語の構造とパターンを学習します。\n",
    "\n",
    "![GPTzeroshot](https://github.com/yanwunhao/gonken-lesson-build-llm-from-scratch/blob/main/figs/key.png?raw=true)\n",
    "\n",
    "この部分はGPT-2論文の核心的な洞察を説明しています。「言語モデルは教師なしマルチタスク学習器である」というタイトルが示すように、GPT-2の革新的な発見は、言語モデルが明示的な教師データなしに多様なタスクを学習できることです。\n",
    "\n",
    "論文は重要な観察を述べています：McCann et al. (2018)のような従来のマルチタスク学習では、どの記号を予測すべきかを明示的に指定する必要がありました。\n",
    "\n",
    "しかしGPT-2は、教師なし目的関数（次の単語予測）と教師あり目的関数の違いは、実は評価する系列の部分集合だけであることを指摘します。\n",
    "\n",
    "この洞察により、十分に大きな言語モデルは、教師なし学習を通じてマルチタスク学習を実現できる可能性が開かれました。\n",
    "\n",
    "表1の翻訳例は特に興味深いです。WebTextの訓練データには、自然に発生する翻訳のデモンストレーションが含まれていました：\n",
    "\n",
    "「Je ne suis pas un imbecile [I'm not a fool].」のように、フランス語の後に英訳が括弧内に示される例。\n",
    "\n",
    "「Mentez mentez, il en restera toujours quelque chose」という文に「Lie lie something will always remain」という翻訳が続く例。\n",
    "\n",
    "映画のタイトル「Brevet Sans Garantie Du Gouvernement」が「Patented without government warranty」と翻訳される例。\n",
    "\n",
    "これらの例が示すのは、GPT-2が訓練中にこのような文脈内の翻訳パターンを学習し、「translate to French:」や「As-tu aller au cinéma?, or Did you go to the movies?」のような形式を理解できるようになったということです。\n",
    "\n",
    "\n",
    "**「教師あり目的関数は教師なし目的関数と同じだが、系列の部分集合でのみ評価される。したがって、教師なし目的関数の大域的最小値は、教師あり目的関数の大域的最小値でもある」**\n",
    "\n",
    "\n",
    "従来の教師あり学習では、「質問→答え」のペアを用意し、モデルに答えの部分だけを予測させます。一方、言語モデルは系列全体のすべてのトークンを予測します。GPT-2の著者たちが気づいたのは、これらは実は同じ最適化問題であるということです——違いは損失を計算する場所だけです。\n",
    "\n",
    "具体例で説明すると：\n",
    "- 教師あり翻訳：「Bonjour → Hello」（Helloの部分だけで損失を計算）\n",
    "- 言語モデル：「Translate to English: Bonjour means Hello」（全トークンで損失を計算）\n",
    "\n",
    "もし言語モデルが完璧に次の単語を予測できるなら、それは必然的に「Bonjour」の後に「Hello」を生成することも学習しているはずです。\n",
    "\n",
    "つまり、**より一般的な問題（全系列の予測）を解くことで、特定の問題（翻訳、QA、要約など）も同時に解いている**のです。\n",
    "\n",
    "この理論的保証があるからこそ、GPT-2やその後継モデルは、ただひたすら次の単語を予測する訓練をするだけで、驚くほど多様なタスクを実行できるようになります。nanoGPTも同じ原理で動作します——シンプルな自己回帰的予測が、実は普遍的な問題解決能力につながるのです。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8fbb5c",
   "metadata": {},
   "source": [
    "## nanoGPT\n",
    "\n",
    "GPT-2が証明した「次単語予測だけでマルチタスク学習が可能」という理論を、実際に手を動かして確認してみましょう。\n",
    "\n",
    "nanoGPTを使えば、ノートパソコンで本物のGPTを訓練できます。環境構築も簡単で、PyTorchさえあれば動きます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fe42e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (2.4.1)\n",
      "Requirement already satisfied: numpy in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (2.1.1)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: datasets in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (4.3.0)\n",
      "Requirement already satisfied: tiktoken in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (0.12.0)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.22.3-py3-none-macosx_12_0_arm64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: tqdm in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from torch) (2024.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from transformers) (2025.10.23)\n",
      "Requirement already satisfied: requests in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: click>=8.0.1 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from wandb) (8.3.0)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from wandb) (4.3.6)\n",
      "Collecting protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 (from wandb)\n",
      "  Downloading protobuf-6.33.0-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: pydantic<3 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from wandb) (2.10.6)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-2.43.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: anyio in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (4.8.0)\n",
      "Requirement already satisfied: certifi in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from pydantic<3->wandb) (2.27.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wandb-0.22.3-py3-none-macosx_12_0_arm64.whl (18.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.8/18.8 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-6.33.0-cp39-abi3-macosx_10_9_universal2.whl (427 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl (432 kB)\n",
      "Downloading sentry_sdk-2.43.0-py2.py3-none-any.whl (400 kB)\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, sentry-sdk, safetensors, protobuf, huggingface-hub, gitdb, tokenizers, gitpython, wandb, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 1.0.1\n",
      "    Uninstalling huggingface-hub-1.0.1:\n",
      "      Successfully uninstalled huggingface-hub-1.0.1\n",
      "Successfully installed gitdb-4.0.12 gitpython-3.1.45 huggingface-hub-0.36.0 protobuf-6.33.0 safetensors-0.6.2 sentry-sdk-2.43.0 smmap-5.0.2 tokenizers-0.22.1 transformers-4.57.1 wandb-0.22.3\n"
     ]
    }
   ],
   "source": [
    "!pip install torch numpy transformers datasets tiktoken wandb tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3f77ae",
   "metadata": {},
   "source": [
    "まず必要なパッケージをインストールします。nanoGPTの実行に必要な最小限のライブラリセットです：\n",
    "\n",
    "```bash\n",
    "pip install torch numpy transformers datasets tiktoken wandb tqdm\n",
    "```\n",
    "\n",
    "**各パッケージの役割：**\n",
    "- `torch`: PyTorchフレームワーク。ニューラルネットワークの構築と訓練の基盤\n",
    "- `numpy`: 数値計算。データの前処理に使用\n",
    "- `transformers`: HuggingFaceのライブラリ。事前訓練済みモデルのダウンロードに使用\n",
    "- `datasets`: HuggingFaceのデータセットライブラリ\n",
    "- `tiktoken`: OpenAIのトークナイザー。テキストをトークンに分割\n",
    "- `wandb`: Weights & Biases。訓練の可視化（オプション、スキップ可）\n",
    "- `tqdm`: プログレスバーの表示\n",
    "\n",
    "インストールには1-2分程度かかります。GPUがある場合は、CUDAバージョンに対応したPyTorchがインストールされているか確認してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df547d8a",
   "metadata": {},
   "source": [
    "### 作業ディレクトリの設定\n",
    "\n",
    "このノートブックはnanoGPTプロジェクトと同じ階層に配置されているため、まずnanoGPTディレクトリに移動します："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "177abbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('nanoGPT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf3a8c1",
   "metadata": {},
   "source": [
    "シェイクスピアデータセットを訓練用に準備します。\n",
    "\n",
    "文字レベルのトークン化は最もシンプルな方法です。GPT-2は本来BPE（Byte Pair Encoding）を使用しますが、教育目的では文字レベルの方が理解しやすく、訓練も速いです。\n",
    "\n",
    "準備が完了すると、data/shakespeare_char/ディレクトリに訓練データが保存されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bfee4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 1,115,394\n",
      "all the unique characters: \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "vocab size: 65\n",
      "train has 1,003,854 tokens\n",
      "val has 111,540 tokens\n"
     ]
    }
   ],
   "source": [
    "!python data/shakespeare_char/prepare.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2918133f",
   "metadata": {},
   "source": [
    "### GPUを使った訓練の実行\n",
    "\n",
    "GPUが利用可能な場合、小規模なGPTモデルを高速に訓練できます。用意されている設定ファイル config/train_shakespeare_char.py を使用します："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaf0462",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py config/train_shakespeare_char.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b21009a",
   "metadata": {},
   "source": [
    "### 訓練済みモデルからのテキスト生成\n",
    "\n",
    "訓練が完了したら、モデルを使ってシェイクスピア風のテキストを生成してみましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070446c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python sample.py --out_dir=out-shakespeare-char"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23c2742",
   "metadata": {},
   "source": [
    "### GPT-2の再現実験\n",
    "\n",
    "ここからは本格的なGPT-2の再現実験に入ります。OpenWebTextデータセットを使用して、実際のGPT-2に近い訓練を行います："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4f6261",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python data/openwebtext/prepare.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021210cc",
   "metadata": {},
   "source": [
    "**OpenWebTextデータセットについて：**\n",
    "\n",
    "GPT-2の訓練に使用されたWebTextの公開版再現\n",
    "Redditで3カルマ以上を獲得したリンク先のWebページを収集\n",
    "約40GBのテキストデータ（800万ドキュメント）\n",
    "\n",
    "**処理内容：**\n",
    "\n",
    "HuggingFaceからOpenWebTextをダウンロード（初回は時間がかかります）\n",
    "GPT-2のトークナイザー（BPE、50257語彙）でエンコード\n",
    "訓練・検証用にシャード分割して保存\n",
    "\n",
    "### GPT-2（124M）の本格訓練\n",
    "\n",
    "複数GPUを使った本格的なGPT-2訓練コマンドです："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fe2533",
   "metadata": {},
   "outputs": [],
   "source": [
    "!torchrun --standalone --nproc_per_node=8 train.py config/train_gpt2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdccf7e3",
   "metadata": {},
   "source": [
    "**コマンドの説明：**\n",
    "\n",
    "torchrun: PyTorchの分散訓練ランチャー\n",
    "--standalone: 単一ノード（1台のマシン）で実行\n",
    "--nproc_per_node=8: 8枚のGPUを使用\n",
    "config/train_gpt2.py: GPT-2 124Mモデルの設定\n",
    "\n",
    "**モデル仕様（GPT-2 124M）：**\n",
    "\n",
    "パラメータ数：1億2400万\n",
    "層数：12層\n",
    "隠れ層次元：768\n",
    "アテンションヘッド：12個"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7562013",
   "metadata": {},
   "source": [
    "### 現実的な訓練オプション 単一GPUの場合："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ac47d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py config/train_gpt2.py --device=cuda --compile=False --eval_iters=20 --batch_size=12 --block_size=1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a821d5",
   "metadata": {},
   "source": [
    "### ファインチューニング\n",
    "\n",
    "ファインチューニングは、事前訓練済みモデルを新しいタスクやドメインに適応させる技術です。訓練との違いは、ゼロからではなく既存の知識を活用することです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9073e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py config/finetune_shakespeare.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d32f95f",
   "metadata": {},
   "source": [
    "## 応用実験：特定の感情でテキストを生成できのためのファインチューニング\n",
    "\n",
    "シェイクスピアの文体学習に加えて、より実用的なタスク「感情認識」のファインチューニング実験を用意しました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb42be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データディレクトリを作成\n",
    "!mkdir -p data/goemotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4933944",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python data/goemotion/prepare.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd6a488",
   "metadata": {},
   "source": [
    "**GoEmotionsデータセットについて：**\n",
    "- Googleが公開したRedditコメントデータセット\n",
    "- 27種類の感情ラベル（joy, anger, fear, surprise等）\n",
    "- 約5万件のコメント\n",
    "\n",
    "**データ形式の工夫：**\n",
    "```\n",
    "Emotion: joy\n",
    "Text: This made my day! Thank you so much!\n",
    "<|endoftext|>\n",
    "\n",
    "この形式により、GPT-2は「感情→テキスト」の関係を学習します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e08542c",
   "metadata": {},
   "source": [
    "### ファインチューニングの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c736b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py config/finetune_goemotion.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dede77de",
   "metadata": {},
   "source": [
    "### 感情条件付きテキスト生成\n",
    "訓練後、特定の感情でテキストを生成できます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94d75e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-goemotion\n",
      "Overriding: start = Emotion: joy\\nText:\n",
      "Overriding: max_new_tokens = 50\n",
      "Overriding: num_samples = 1\n",
      "/Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages/torch/amp/autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/Users/rubieywh/workspace/gonken-lesson-build-llm-from-scratch/nanoGPT/sample.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(ckpt_path, map_location=device)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rubieywh/workspace/gonken-lesson-build-llm-from-scratch/nanoGPT/sample.py\", line 38, in <module>\n",
      "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
      "  File \"/Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages/torch/serialization.py\", line 1097, in load\n",
      "    return _load(\n",
      "  File \"/Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages/torch/serialization.py\", line 1525, in _load\n",
      "    result = unpickler.load()\n",
      "  File \"/Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages/torch/serialization.py\", line 1492, in persistent_load\n",
      "    typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n",
      "  File \"/Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages/torch/serialization.py\", line 1466, in load_tensor\n",
      "    wrap_storage=restore_location(storage, location),\n",
      "  File \"/Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages/torch/serialization.py\", line 1389, in restore_location\n",
      "    return default_restore_location(storage, map_location)\n",
      "  File \"/Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages/torch/serialization.py\", line 414, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"/Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages/torch/serialization.py\", line 391, in _deserialize\n",
      "    device = _validate_device(location, backend_name)\n",
      "  File \"/Users/rubieywh/miniforge3/envs/dl_env/lib/python3.10/site-packages/torch/serialization.py\", line 364, in _validate_device\n",
      "    raise RuntimeError(f'Attempting to deserialize object on a {backend_name.upper()} '\n",
      "RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n"
     ]
    }
   ],
   "source": [
    "!python sample.py --out_dir=out-goemotion --start=\"Emotion: joy\\nText:\" --max_new_tokens=50 --num_samples=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
