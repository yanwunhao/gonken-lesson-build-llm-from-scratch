{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1a3606d",
   "metadata": {},
   "source": [
    "# レッスン 01  Predict-Next-Token\n",
    "\n",
    "このチュートリアルでは、言語モデルの基本メカニズムである「次のトークン予測」（Predict-Next-Token）を深く理解していきます。ゼロから文字レベルの言語モデルを構築し、シェイクスピアの文体を学習させます。この実践プロジェクトを通じて、ニューラルネットワークがどのようにテキストパターンを学習し、特定のスタイルのテキストを生成するかを体験できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89132eb3",
   "metadata": {},
   "source": [
    "## Section 1 シェイクスピアテキストデータセット\n",
    "言語モデルの構築を始める前に、まずトレーニングデータを準備する必要があります。ここでは古典的な「Tiny Shakespeare」データセット——シェイクスピアの全作品を含むテキストコレクションを使用します。\n",
    "\n",
    "### なぜこのデータセットを選ぶのか？\n",
    "\n",
    "* 独特なテキストスタイル：シェイクスピアの古英語の文体は特徴的で、モデルの学習効果を観察しやすい\n",
    "* 適度なデータ量：約1MBのテキストで、高速なトレーニングと実験に適している\n",
    "* 古典的な教育事例：言語モデル入門チュートリアルで広く使用されている\n",
    "\n",
    "### データセットのダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ac4b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a515c3b6",
   "metadata": {},
   "source": [
    "このコマンドでGitHubからinput.txtファイルを現在のディレクトリにダウンロードします。\n",
    "\n",
    "### テキストデータの読み込み\n",
    "\n",
    "このコードは、テキストファイルを読み込み、データセットの規模を確認する方法を示しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f7712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715692bd",
   "metadata": {},
   "source": [
    "with open() ステートメント\n",
    "\n",
    "* with はPythonのコンテキストマネージャーで、ファイルを自動的に閉じ、リソースリークを防ぎます\n",
    "* エラーが発生しても、ファイルは正しく閉じられます\n",
    "* \"r\": 読み取りモード（read mode）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94b4f68",
   "metadata": {},
   "source": [
    "### テキストの冒頭を確認\n",
    "テキストの冒頭を確認任意のデータセットを処理する前に、実際の内容をプレビューすることは非常に重要なステップです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4db7782",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a6fd6",
   "metadata": {},
   "source": [
    "## Section 2 Pytorchをインストールする\n",
    "\n",
    "PyTorchをインストールする前に、コンピュータのGPU構成を確認する必要があります。ニューラルネットワークのトレーニング時、GPUは計算速度を大幅に向上させます（通常CPUの100倍以上速い）。\n",
    "\n",
    "### ステップ1：GPUとCUDAバージョンの確認\n",
    "\n",
    "ターミナルまたはJupyter Notebookで以下のコマンドを実行します："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d367ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f80c47",
   "metadata": {},
   "source": [
    "### コマンドの説明\n",
    "\n",
    "nvidia-smi (NVIDIA System Management Interface)\n",
    "\n",
    "* NVIDIAが公式に提供するGPU監視ツール\n",
    "\n",
    "* GPUモデル、ドライババージョン、CUDAバージョン、VRAMの使用状況などの重要な情報を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aeadc7",
   "metadata": {},
   "source": [
    "### 出力例の解説\n",
    "\n",
    "最初の行：ドライバとCUDA情報\n",
    "\n",
    "* NVIDIA-SMI 580.65.06：NVIDIAドライババージョン\n",
    "* Driver Version: 580.65.06：ドライバプログラムバージョン\n",
    "* CUDA Version: 13.0：最重要！ サポートされる最高CUDAバージョン\n",
    "\n",
    "GPU詳細情報（GPU毎に1行）\n",
    "\n",
    "* GPU 0, 1：2枚のGPUが検出されました\n",
    "* NVIDIA H100 80GB HBM3：GPUモデル\n",
    "* 26C：現在の温度26℃\n",
    "* 69W / 700W：現在の消費電力/最大消費電力\n",
    "* 4MiB / 81559MiB：VRAM使用状況 - 使用中4MB / 合計約80GB\n",
    "* 0%：GPU利用率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd7a86b",
   "metadata": {},
   "source": [
    "### ステップ2: PyTorchのインストール\n",
    "\n",
    "PyTorch公式サイトのインストールページにアクセス https://pytorch.org/\n",
    "\n",
    "環境に応じて適切な設定を選択します：\n",
    "\n",
    "![install_pytorch](https://github.com/yanwunhao/gonken-lesson-build-llm-from-scratch/blob/main/figs/install_pytorch.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7cc30d",
   "metadata": {},
   "source": [
    "### インストールの確認\n",
    "\n",
    "インストール完了後、以下のコードを実行して確認："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb9070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# PyTorchバージョンの確認\n",
    "print(f\"PyTorchバージョン: {torch.__version__}\")\n",
    "\n",
    "# CUDAが利用可能か確認\n",
    "print(f\"CUDAが利用可能: {torch.cuda.is_available()}\")\n",
    "\n",
    "# CUDAが利用可能な場合、GPU情報を表示\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"利用可能なGPU数: {torch.cuda.device_count()}\")\n",
    "    print(f\"現在のGPU: {torch.cuda.get_device_name(0)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
